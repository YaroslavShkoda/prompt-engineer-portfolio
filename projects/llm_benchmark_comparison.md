## Проект: Сравнение LLM — бенчмарк моделей KIMI K2, GLM-4.5, Qwen-3-235B и Deepseek

**Цель**: Оценить производительность разных LLM в задачах генерации текста, анализа данных и написания кода для выбора оптимальной модели под конкретные кейсы.

**Методика**:
- Подготовлено по 10 тестовых задач в каждой категории: текст, анализ, код
- Все промпты стандартизированы, с чёткими инструкциями и ожидаемым форматом
- Оценка по критериям: точность, скорость, структура, логика, частота ошибок
- Каждая модель запускалась при фиксированных параметрах (temperature=0.3, max_tokens=512)

**Результаты**:
- **KIMI K2**: Лучше всех справляется с длинными текстами и контекстом (>32K)
- **GLM-4.5**: Высокая точность в аналитике и структурировании данных
- **Qwen-3-235B**: Лидер в генерации и рефакторинге кода
- **Deepseek**: Быстрый и стабильный, хорош в балансе всех задач

**Вывод**: Выбор модели зависит от задачи. Создан чек-лист для быстрого подбора LLM под проект.

**Использовано**: KIMI K2, GLM-4.5, Qwen-3-235B, Deepseek, Python (обработка результатов), JSON (хранение тестов и выводов)
